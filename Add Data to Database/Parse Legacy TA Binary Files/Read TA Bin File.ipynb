{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import struct # module for unpacking binary files\n",
    "import os # module for using OS tools to navigate directories\n",
    "import datetime as dt # module for converting time stamps to/from strings\n",
    "import pyodbc # Module for ODBC for python to connect to database\n",
    "\n",
    "def readTABin(fileName):\n",
    "    with open(fileName,mode='rb') as f:\n",
    "\n",
    "        # unpackP specifies the unpack parameters as 'name', type size (bytes), type char\n",
    "        unpackP = [['desc',1,'s'],\n",
    "                   ['avgs',4,'l'],\n",
    "                   ['gPos',8,'d'],\n",
    "                   ['delays',8,'d']]; \n",
    "        \n",
    "        # define expSet as a dictionary, this will be returned to the caller\n",
    "        expSet = {}\n",
    "\n",
    "        for packRule in unpackP:\n",
    "            # LabVIEW encodes binary data as header-data. \n",
    "            # The header is type unsigned long and contains the data size in bytes\n",
    "            b = f.read(4) # long is 4 bytes\n",
    "            h = struct.unpack('>L',b)[0] # upack method returns type tuple, take 1st element\n",
    "            b = f.read(h*packRule[1]) # The char array is h bytes * type size\n",
    "            expSet[packRule[0]] = (struct.unpack('>'+str(h)+packRule[2],b))\n",
    "\n",
    "        # format expSet for easier reading\n",
    "        expSet['desc'] = expSet['desc'][0].decode('utf-8')\n",
    "        expSet['avgs'] = {'frames':expSet['avgs'][0],\n",
    "                          'gPos':expSet['avgs'][1],\n",
    "                          'rpts':expSet['avgs'][2]}\n",
    "        \n",
    "    return expSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample L, Fluence dependence measurements at pH13 and 100mM Na+ ionic concentration\n"
     ]
    }
   ],
   "source": [
    "# Test readTaBin function\n",
    "# Return the current working directory, which will be the script dir when run in jupyter notebook\n",
    "parentDir = os.path.abspath(''); \n",
    "fileName = os.path.join(parentDir,'SampleData','19-12-05_14h53m12s_0p04Fl_0V_pH13_100mM_460nm_cont_0-2ns_spol');\n",
    "\n",
    "expSet = readTABin(fileName)\n",
    "print(expSet['desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract Metadata from TA bin files inside a given directory\n",
    "filePath = 'C:\\\\Users\\\\User\\\\Documents\\\\UserData Backup\\\\TA data\\\\Ilya'\n",
    "\n",
    "# uses os.walk to recursively search dirs in filePath, excludes files in paths that contains case-insensitive 'bad' and files that contain extensions\n",
    "files = [[fiDir,fi] for fiDir,_,fiList in os.walk(filePath) for fi in fiList if not ('bad' in fiDir or 'Bad' in fiDir) and '.' not in fi]\n",
    "\n",
    "# retrieve all descriptions in the file list\n",
    "descs = [readTABin(os.path.join(fi[0],fi[1]))['desc'] for fi in files]\n",
    "\n",
    "# Extract timestring from files into a list\n",
    "tsStrs = [fi[1][0:18] for fi in files]\n",
    "\n",
    "# Format timestring into a datetime object list\n",
    "tsDT = [dt.datetime.strptime(ts,'%y-%m-%d_%Hh%Mm%Ss') for ts in tsStrs]\n",
    "\n",
    "# Format the datetime object list into a SQL string\n",
    "tsStrs = [str(ts) for ts in tsDT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert legacy TR bin data into Raman Database\n",
    "\n",
    "# construct a connection object with DSN Raman Access and\n",
    "conn = pyodbc.connect('DSN=Raman Access')\n",
    "\n",
    "# Create a cursor to execute SQL INSERT\n",
    "crsr = conn.cursor()\n",
    "\n",
    "# Set autocommit to false so that database is updated only if query executes without error\n",
    "conn.autocommit = False\n",
    "\n",
    "# try to execute query\n",
    "try:\n",
    "    # Combine different lists and loop over their elements\n",
    "    for (fi, des, ts) in zip(files, descs, tsStrs):\n",
    "        # Execute parameterized query\n",
    "        crsr = crsr.execute('INSERT INTO TRAcquisition '\n",
    "                            '(FilePath, FileName, Description, SoftwareVersionID, DatabaseVersionID, [TimeStamp])' \n",
    "                            'VALUES (?, ?, ?, ?, ?, ?);', fi[0], fi[1], des, 2, 2, ts)\n",
    "except pyodbc.DatabaseError as err:\n",
    "    # Undo any damage and return the exception to the user\n",
    "    conn.rollback()\n",
    "    print(err)\n",
    "else:\n",
    "    # commit record updates to database\n",
    "    conn.commit()\n",
    "    \n",
    "# Note: Close connection by shutting down notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
